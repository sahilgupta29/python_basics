{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "216bd918",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "course_name = ['Data Science', 'Machine Learning', 'Big Data', 'Data Engineer']\n",
    "duration=[2,3,6,4]\n",
    "df=pd.DataFrame(data={'course_name':course_name,'duration':duration})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5c427d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>course_name</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Big Data</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        course_name  duration\n",
       "0      Data Science         2\n",
       "1  Machine Learning         3\n",
       "2          Big Data         6\n",
       "3     Data Engineer         4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f09646",
   "metadata": {},
   "source": [
    "Q1.Write a code to print the data present in the second row of the dataframe, df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6cc5b5bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "course_name    Machine Learning\n",
       "duration                      3\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5309e5d",
   "metadata": {},
   "source": [
    "Q2. What is the difference between the functions loc and iloc in pandas.DataFrame?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe5bda47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"In pandas, loc and iloc are two different functions used to access data from a DataFrame. They are used for indexing and selecting rows and columns from the DataFrame in different ways:\\n\\nloc (Label-based Indexing):\\n\\nloc is primarily used for label-based indexing, meaning you can access data using row and column labels.\\nThe syntax for loc is df.loc[row_label, column_label].\\nThe row label can be an index label (integer or string) of the DataFrame, and the column label can be the column name.\\nIt allows you to access data based on the actual labels assigned to rows and columns, which can be non-integer and non-sequential.\\nFor example: df.loc[2, \\'course_name\\'] will give you the value in the row with label \\'2\\' and column with label \\'course_name\\'.\\niloc (Integer-based Indexing):\\n\\niloc is used for integer-based indexing, meaning you can access data using integer positions (row and column indices) of the DataFrame.\\nThe syntax for iloc is df.iloc[row_index, column_index].\\nThe row index and column index must be integer values, and they start from 0 for the first row/column, 1 for the second row/column, and so on.\\nIt allows you to access data based on the numerical position of rows and columns, regardless of the actual labels assigned to them.\\nFor example: df.iloc[1, 0] will give you the value in the second row (index 1) and first column (index 0).'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\"In pandas, loc and iloc are two different functions used to access data from a DataFrame. They are used for indexing and selecting rows and columns from the DataFrame in different ways:\n",
    "\n",
    "loc (Label-based Indexing):\n",
    "\n",
    "loc is primarily used for label-based indexing, meaning you can access data using row and column labels.\n",
    "The syntax for loc is df.loc[row_label, column_label].\n",
    "The row label can be an index label (integer or string) of the DataFrame, and the column label can be the column name.\n",
    "It allows you to access data based on the actual labels assigned to rows and columns, which can be non-integer and non-sequential.\n",
    "For example: df.loc[2, 'course_name'] will give you the value in the row with label '2' and column with label 'course_name'.\n",
    "iloc (Integer-based Indexing):\n",
    "\n",
    "iloc is used for integer-based indexing, meaning you can access data using integer positions (row and column indices) of the DataFrame.\n",
    "The syntax for iloc is df.iloc[row_index, column_index].\n",
    "The row index and column index must be integer values, and they start from 0 for the first row/column, 1 for the second row/column, and so on.\n",
    "It allows you to access data based on the numerical position of rows and columns, regardless of the actual labels assigned to them.\n",
    "For example: df.iloc[1, 0] will give you the value in the second row (index 1) and first column (index 0).\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a338d5",
   "metadata": {},
   "source": [
    "Q3. Reindex the given dataframe using a variable, reindex = [3,0,1,2] and store it in the variable, new_df\n",
    "then find the output for both new_df.loc[2] and new_df.iloc[2]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef7f327b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "course_name    Big Data\n",
       "duration              6\n",
       "Name: 2, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df=df.reindex([3,0,1,2])\n",
    "new_df.loc[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04bbb3d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "course_name    Machine Learning\n",
       "duration                      3\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "674693de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"here we find the diffrence in answer because when we use loc new_df.loc[2] gives the row with label (index) '2' in the DataFrame. The label '2' corresponds to the row with the course name 'Big Data' and duration '6',\\nand in new_df.iloc[2] gives the row with position (index) 2 in the DataFrame. The position 2 corresponds to the row with the course name 'Machine Learning' and duration '3'.\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"here we find the diffrence in answer because when we use loc new_df.loc[2] gives the row with label (index) '2' in the DataFrame. The label '2' corresponds to the row with the course name 'Big Data' and duration '6',\n",
    "and in new_df.iloc[2] gives the row with position (index) 2 in the DataFrame. The position 2 corresponds to the row with the course name 'Machine Learning' and duration '3'.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a8ab7db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "columns = ['column_1', 'column_2', 'column_3', 'column_4', 'column_5', 'column_6']\n",
    "indices = [1,2,3,4,5,6]\n",
    "#Creating a dataframe:\n",
    "df1 = pd.DataFrame(np.random.rand(6,6), columns = columns, index = indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6c0240d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column_1</th>\n",
       "      <th>column_2</th>\n",
       "      <th>column_3</th>\n",
       "      <th>column_4</th>\n",
       "      <th>column_5</th>\n",
       "      <th>column_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.624986</td>\n",
       "      <td>0.477029</td>\n",
       "      <td>0.283545</td>\n",
       "      <td>0.902134</td>\n",
       "      <td>0.486655</td>\n",
       "      <td>0.736340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.462728</td>\n",
       "      <td>0.531863</td>\n",
       "      <td>0.935035</td>\n",
       "      <td>0.577418</td>\n",
       "      <td>0.313788</td>\n",
       "      <td>0.503564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.907766</td>\n",
       "      <td>0.965936</td>\n",
       "      <td>0.100642</td>\n",
       "      <td>0.906348</td>\n",
       "      <td>0.501396</td>\n",
       "      <td>0.371852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.116880</td>\n",
       "      <td>0.717898</td>\n",
       "      <td>0.823104</td>\n",
       "      <td>0.432861</td>\n",
       "      <td>0.585227</td>\n",
       "      <td>0.655244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.586559</td>\n",
       "      <td>0.687951</td>\n",
       "      <td>0.410200</td>\n",
       "      <td>0.796924</td>\n",
       "      <td>0.065886</td>\n",
       "      <td>0.687740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.442679</td>\n",
       "      <td>0.868808</td>\n",
       "      <td>0.935749</td>\n",
       "      <td>0.510228</td>\n",
       "      <td>0.405591</td>\n",
       "      <td>0.840523</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   column_1  column_2  column_3  column_4  column_5  column_6\n",
       "1  0.624986  0.477029  0.283545  0.902134  0.486655  0.736340\n",
       "2  0.462728  0.531863  0.935035  0.577418  0.313788  0.503564\n",
       "3  0.907766  0.965936  0.100642  0.906348  0.501396  0.371852\n",
       "4  0.116880  0.717898  0.823104  0.432861  0.585227  0.655244\n",
       "5  0.586559  0.687951  0.410200  0.796924  0.065886  0.687740\n",
       "6  0.442679  0.868808  0.935749  0.510228  0.405591  0.840523"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4626589b",
   "metadata": {},
   "source": [
    "Q4. Write a code to find the following statistical measurements for the above dataframe df1:\n",
    "(i) mean of each and every column present in the dataframe.\n",
    "(ii) standard deviation of column, ‘column_2’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "30476324",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "column_1    0.523600\n",
       "column_2    0.708247\n",
       "column_3    0.581379\n",
       "column_4    0.687652\n",
       "column_5    0.393091\n",
       "column_6    0.632544\n",
       "dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (i)\n",
    "df1_mean=df1.mean()\n",
    "df1_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "71e33706",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_stds=df1['column_2'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "477b2b92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18828799635595986"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_stds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96986dc6",
   "metadata": {},
   "source": [
    "Q5. Replace the data present in the second row of column, ‘column_2’ by a string variable then find the\n",
    "mean of column, column_2.\n",
    "If you are getting errors in executing it then explain why.\n",
    "[Hint: To replace the data use df1.loc[] and equate this to string data of your choice.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "06f4235c",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"float\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7784\\1214860163.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# Find the mean of 'column_2'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mmean_column_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'column_2'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Mean of 'column_2':\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean_column_2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mmean\u001b[1;34m(self, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  11122\u001b[0m             \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  11123\u001b[0m         ):\n\u001b[1;32m> 11124\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mNDFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumeric_only\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m  11125\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  11126\u001b[0m         \u001b[0msetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"mean\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mmean\u001b[1;34m(self, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  10692\u001b[0m         \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10693\u001b[0m     ) -> Series | float:\n\u001b[1;32m> 10694\u001b[1;33m         return self._stat_function(\n\u001b[0m\u001b[0;32m  10695\u001b[0m             \u001b[1;34m\"mean\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnanops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnanmean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumeric_only\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10696\u001b[0m         )\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_stat_function\u001b[1;34m(self, name, func, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  10644\u001b[0m                 \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumeric_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnumeric_only\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10645\u001b[0m             )\n\u001b[1;32m> 10646\u001b[1;33m         return self._reduce(\n\u001b[0m\u001b[0;32m  10647\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumeric_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnumeric_only\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10648\u001b[0m         )\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_reduce\u001b[1;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[0;32m   4469\u001b[0m                 )\n\u001b[0;32m   4470\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4471\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelegate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4472\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4473\u001b[0m     def _reindex_indexer(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\nanops.py\u001b[0m in \u001b[0;36m_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     91\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minvalid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m                 \u001b[1;31m# we want to transform an object array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\nanops.py\u001b[0m in \u001b[0;36mf\u001b[1;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[0;32m    153\u001b[0m                     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    156\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\nanops.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(values, axis, skipna, mask, **kwargs)\u001b[0m\n\u001b[0;32m    408\u001b[0m             \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    409\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 410\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    411\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    412\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdatetimelike\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\nanops.py\u001b[0m in \u001b[0;36mnanmean\u001b[1;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[0;32m    696\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    697\u001b[0m     \u001b[0mcount\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype_count\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 698\u001b[1;33m     \u001b[0mthe_sum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_ensure_numeric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype_sum\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    699\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    700\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthe_sum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ndim\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py\u001b[0m in \u001b[0;36m_sum\u001b[1;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m     46\u001b[0m def _sum(a, axis=None, dtype=None, out=None, keepdims=False,\n\u001b[0;32m     47\u001b[0m          initial=_NoValue, where=True):\n\u001b[1;32m---> 48\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m def _prod(a, axis=None, dtype=None, out=None, keepdims=False,\n",
      "\u001b[1;31mTypeError\u001b[0m: can only concatenate str (not \"float\") to str"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming 'df1' is the DataFrame provided in the question\n",
    "# If you have a different DataFrame name, replace 'df1' with your DataFrame variable name.\n",
    "\n",
    "# Replace the data in the second row of 'column_2' with a string variable\n",
    "df1.loc[1, 'column_2'] = \"replacement_string\"\n",
    "\n",
    "# Find the mean of 'column_2'\n",
    "mean_column_2 = df1['column_2'].mean()\n",
    "\n",
    "print(\"Mean of 'column_2':\", mean_column_2)\n",
    "\n",
    "\n",
    "To replace the data present in the second row of column 'column_2' with a string variable, you can use the df.loc[] method to access the specific cell and update its value. Then, you can find the mean of 'column_2'. However, there is a potential issue if the data type of 'column_2' is not compatible with the string variable you are trying to replace with.\n",
    "\n",
    "Here's the code to achieve this:\n",
    "\n",
    "python\n",
    "Copy code\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming 'df1' is the DataFrame provided in the question\n",
    "# If you have a different DataFrame name, replace 'df1' with your DataFrame variable name.\n",
    "\n",
    "# Replace the data in the second row of 'column_2' with a string variable\n",
    "df1.loc[1, 'column_2'] = \"replacement_string\"\n",
    "\n",
    "# Find the mean of 'column_2'\n",
    "mean_column_2 = df1['column_2'].mean()\n",
    "\n",
    "print(\"Mean of 'column_2':\", mean_column_2)\n",
    "\"\"\"In this code, I have replaced the data in the second row of 'column_2' with the string \"replacement_string\". However, if the original data in 'column_2' was not a compatible data type (e.g., integer or float),\n",
    "replacing it with a string could cause an error.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8857458b",
   "metadata": {},
   "source": [
    "Q6. What do you understand about the windows function in pandas and list the types of windows\n",
    "functions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "78327282",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In pandas, a \"window\" refers to a set of rows within a DataFrame that are used for computing and performing operations.\\nWindow functions allow you to perform calculations on a specific subset of data defined by this window. These functions are essential for tasks that require computing aggregated results or performing calculations over a sliding or rolling window of data, such as time series analysis, moving averages, cumulative sums, and more.\\nTypes of Window Functions in pandas:\\n\\nRolling Window Functions:\\n\\nRolling window functions are used to perform calculations on a fixed-size rolling window of data.\\nExample: df[\\'column\\'].rolling(window=3).mean()\\nExpanding Window Functions:\\n\\nExpanding window functions calculate statistics for all data points in a DataFrame up to the current point, gradually expanding the window.\\nExample: df[\\'column\\'].expanding().sum()'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"In pandas, a \"window\" refers to a set of rows within a DataFrame that are used for computing and performing operations.\n",
    "Window functions allow you to perform calculations on a specific subset of data defined by this window. These functions are essential for tasks that require computing aggregated results or performing calculations over a sliding or rolling window of data, such as time series analysis, moving averages, cumulative sums, and more.\n",
    "Types of Window Functions in pandas:\n",
    "\n",
    "Rolling Window Functions:\n",
    "\n",
    "Rolling window functions are used to perform calculations on a fixed-size rolling window of data.\n",
    "Example: df['column'].rolling(window=3).mean()\n",
    "Expanding Window Functions:\n",
    "\n",
    "Expanding window functions calculate statistics for all data points in a DataFrame up to the current point, gradually expanding the window.\n",
    "Example: df['column'].expanding().sum()\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6b8f21",
   "metadata": {},
   "source": [
    "Q7. Write a code to print only the current month and year at the time of answering this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "de21c194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Month: 7\n",
      "Current Year: 2023\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Get the current date and time\n",
    "current_datetime = datetime.now()\n",
    "\n",
    "# Extract the current month and year from the current date\n",
    "current_month = current_datetime.month\n",
    "current_year = current_datetime.year\n",
    "\n",
    "# Print the current month and year\n",
    "print(\"Current Month:\", current_month)\n",
    "print(\"Current Year:\", current_year)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b305d95c",
   "metadata": {},
   "source": [
    "Q8. Write a Python program that takes in two dates as input (in the format YYYY-MM-DD) and\n",
    "calculates the difference between them in days, hours, and minutes using Pandas time delta. The\n",
    "program should prompt the user to enter the dates and display the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012fb351",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def calculate_time_difference(date1, date2):\n",
    "    try:\n",
    "        # Convert the input dates to pandas datetime objects\n",
    "        date1 = pd.to_datetime(date1)\n",
    "        date2 = pd.to_datetime(date2)\n",
    "\n",
    "        # Calculate the time difference using pandas timedelta\n",
    "        time_difference = date2 - date1\n",
    "\n",
    "        # Extract the days, hours, and minutes from the timedelta\n",
    "        days = time_difference.days\n",
    "        hours = time_difference.seconds // 3600\n",
    "        minutes = (time_difference.seconds // 60) % 60\n",
    "\n",
    "        return days, hours, minutes\n",
    "\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "# Prompt the user to enter the two dates\n",
    "date1_input = input(\"Enter the first date (YYYY-MM-DD): \")\n",
    "date2_input = input(\"Enter the second date (YYYY-MM-DD): \")\n",
    "\n",
    "# Calculate the time difference between the two dates\n",
    "result = calculate_time_difference(date1_input, date2_input)\n",
    "\n",
    "if result is not None:\n",
    "    days, hours, minutes = result\n",
    "    print(\"Time Difference:\")\n",
    "    print(f\"{days} days, {hours} hours, and {minutes} minutes.\")\n",
    "else:\n",
    "    print(\"Invalid date format. Please enter dates in the format 'YYYY-MM-DD'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164f53ba",
   "metadata": {},
   "source": [
    "Q9. Write a Python program that reads a CSV file containing categorical data and converts a specified\n",
    "column to a categorical data type. The program should prompt the user to enter the file path, column\n",
    "name, and category order, and then display the sorted data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a529bdc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def convert_to_categorical(df, column_name, category_order):\n",
    "    # Convert the specified column to a categorical data type\n",
    "    df[column_name] = pd.Categorical(df[column_name], categories=category_order, ordered=True)\n",
    "    return df\n",
    "\n",
    "def main():\n",
    "    # Prompt the user to enter the file path, column name, and category order\n",
    "    file_path = input(\"Enter the CSV file path: \")\n",
    "    column_name = input(\"Enter the column name to convert to categorical: \")\n",
    "    category_order = input(\"Enter the category order (comma-separated): \").split(\",\")\n",
    "\n",
    "    try:\n",
    "        # Read the CSV file into a DataFrame\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # Convert the specified column to a categorical data type\n",
    "        df = convert_to_categorical(df, column_name, category_order)\n",
    "\n",
    "        # Display the sorted data based on the category order\n",
    "        sorted_df = df.sort_values(by=column_name)\n",
    "        print(sorted_df)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: File not found. Please check the file path.\")\n",
    "    except KeyError:\n",
    "        print(f\"Error: Column '{column_name}' not found in the CSV file.\")\n",
    "    except ValueError:\n",
    "        print(\"Error: Invalid category order format. Please enter comma-separated categories.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f2bd84",
   "metadata": {},
   "source": [
    "Q10. Write a Python program that reads a CSV file containing sales data for different products and\n",
    "visualizes the data using a stacked bar chart to show the sales of each product category over time. The\n",
    "program should prompt the user to enter the file path and display the chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f704b602",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_stacked_bar_chart(data):\n",
    "    # Grouping data by time (assuming there's a 'Time' column in the CSV)\n",
    "    grouped_data = data.groupby(['Time', 'Product Category'])['Sales'].sum().unstack()\n",
    "\n",
    "    # Plotting the stacked bar chart\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    grouped_data.plot(kind='bar', stacked=True, rot=45)\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Sales')\n",
    "    plt.title('Sales of Product Categories Over Time')\n",
    "    plt.legend(title='Product Category')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def main():\n",
    "    file_path = input(\"Enter the file path for the CSV file: \")\n",
    "\n",
    "    try:\n",
    "        # Reading the CSV file using pandas\n",
    "        data = pd.read_csv(file_path)\n",
    "\n",
    "        # Displaying the stacked bar chart\n",
    "        plot_stacked_bar_chart(data)\n",
    "    except FileNotFoundError:\n",
    "        print(\"File not found. Please provide a valid file path.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5610a73a",
   "metadata": {},
   "source": [
    "Q11. You are given a CSV file containing student data that includes the student ID and their test score. Write\n",
    "a Python program that reads the CSV file, calculates the mean, median, and mode of the test scores, and\n",
    "displays the results in a table.\n",
    "The program should do the followingM\n",
    "I Prompt the user to enter the file path of the CSV file containing the student dataR\n",
    "I Read the CSV file into a Pandas DataFrameR\n",
    "I Calculate the mean, median, and mode of the test scores using Pandas toolsR\n",
    "I Display the mean, median, and mode in a table.\n",
    "Assume the CSV file contains the following columnsM\n",
    "I Student ID: The ID of the studentR\n",
    "I Test Score: The score of the student's test.\n",
    "Example usage of the program:\n",
    "Enter the file path of the CSV file containing the student data: student_data.csv\n",
    "+-----------+--------+\n",
    "| Statistic | Value |\n",
    "+-----------+--------+\n",
    "| Mean | 79.6 |\n",
    "| Median | 82 |\n",
    "| Mode | 85, 90 |\n",
    "+-----------+--------+\n",
    "Assume that the CSV file student_data.csv contains the following data:\n",
    "Student ID,Test Score\n",
    "1,85\n",
    "2,90\n",
    "3,80\n",
    "4,75\n",
    "5,85\n",
    "6,82\n",
    "7,78\n",
    "8,85\n",
    "9,90\n",
    "10,85\n",
    "The program should calculate the mean, median, and mode of the test scores and display the results\n",
    "in a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ba436f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def calculate_statistics(data):\n",
    "    mean_score = data['Test Score'].mean()\n",
    "    median_score = data['Test Score'].median()\n",
    "    mode_score = data['Test Score'].mode()\n",
    "\n",
    "    return mean_score, median_score, mode_score\n",
    "\n",
    "def display_results(mean_score, median_score, mode_score):\n",
    "    result_table = pd.DataFrame({\n",
    "        'Statistic': ['Mean', 'Median', 'Mode'],\n",
    "        'Value': [mean_score, median_score, ', '.join(map(str, mode_score))]\n",
    "    })\n",
    "\n",
    "    print(result_table)\n",
    "\n",
    "def main():\n",
    "    file_path = input(\"Enter the file path of the CSV file containing the student data: \")\n",
    "\n",
    "    try:\n",
    "        # Reading the CSV file into a Pandas DataFrame\n",
    "        data = pd.read_csv(file_path)\n",
    "\n",
    "        # Calculating the mean, median, and mode of the test scores\n",
    "        mean_score, median_score, mode_score = calculate_statistics(data)\n",
    "\n",
    "        # Displaying the results in a table\n",
    "        display_results(mean_score, median_score, mode_score)\n",
    "    except FileNotFoundError:\n",
    "        print(\"File not found. Please provide a valid file path.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d9c136",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
